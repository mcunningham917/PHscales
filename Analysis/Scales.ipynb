{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Global & local vertical scale estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Process results of progressive hypsometry (PH) for a collection of regions and their ensemble of \"supercatchments\" to identify the global and local vertical scales of each. \n",
    "\n",
    "Each supercatchments PH data file provides a set of $h_\\mathrm{outlet}$ and $h_\\mathrm{bench}$ values in tab-separated form. This table of PHBs (progressive hypsometry benches) is converted into an vector of $\\Delta{h} = h_\\mathrm{outlet}-h_\\mathrm{bench}$ values.\n",
    "\n",
    "Kernel density estimation is used to compute a smooth frequency distribution (pdf) of $\\Delta{h}$ assuming a Gaussian kernel with a Silverman bandwidth (narrowed by 75%).\n",
    "\n",
    "The peaks of this distribution, which are the modes of the pdf, are located, and the largest two, which likely constitute the global and local vertical scales, are chosen.\n",
    "\n",
    "The kde pdf is then modeled through least-squares curve-fitting using two Gaussians, whose means are initiated at these two modes respectively, and whose means, standard deviations and relative magnitude are permitted to vary.\n",
    "\n",
    "The result is an estimate of the global and local scales and their spread (one standard deviation) for each supercatchment. These results are gathered into one summary table and exported as a text file.\n",
    "\n",
    "Graphs are plotted to record the kde pdf, the Gaussian-modeled pdf, the raw kde pdf modes and the Gaussian modeled modes aka global and local vertical scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To run this notebook you’ll need to have installed (with `Conda`, `pip` or other package manager) the following packages:\n",
    "  - numpy\n",
    "  - scipy\n",
    "  - matplotlib\n",
    "  - os\n",
    "  - pandas\n",
    "  - sklearn\n",
    "  - json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### How to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Open a terminal\n",
    "2. Assuming you are running `bash`, type: \n",
    "    - `export PHHOME=\"${HOME}/Science/ProgHypso\"` \n",
    "    - or whatever your path to the parent for `PHscales` is\n",
    "3. `cd` to the directory containing the notebook\n",
    "4. Type `jupyter-notebook`, or to choose a specific version, e.g.  `jupyter-notebook-3.7`\n",
    "5. `Cell` -> `Run all`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, pandas as pd, numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_home_path=os.getenv('PHHOME',\n",
    "                os.path.join(os.getenv('HOME'),'Science','ProgHypso'))\n",
    "if ph_home_path is None:\n",
    "    ph_home_path=os.path.join(os.getenv('HOME'),'Science','ProgHypso')\n",
    "ph_scales_path = os.path.join(ph_home_path,'PHscales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figsize = [6, 8]\n",
    "figsize = [8, 6]\n",
    "mpl.rc( 'figure', autolayout=False,  titlesize='Large',dpi=100)\n",
    "mpl.rc( 'lines', linewidth=2.0, markersize=8)\n",
    "mpl.rc( 'font', size=12, family='Arial')\n",
    "mpl.rc( 'axes', labelsize=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth_adjustment_factor = 0.75\n",
    "bandwidth_adjustment_factor\n",
    "example_phb_index = 10\n",
    "default_gaussian_stdev = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir_name=('.'), file_name=None, \n",
    "              file_ext='', key='ph', sep='\\t',\n",
    "              index_col=0, header=0, skip_rows=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dir_name = os.path.join(*dir_name)\n",
    "    if not os.path.exists(dir_name):\n",
    "        print('Cannot find data directory')\n",
    "        raise\n",
    "    try:\n",
    "        file_path = os.path.join(dir_name,file_name+file_ext)\n",
    "        df = pd.read_csv(file_path, sep=sep,\n",
    "                           index_col=index_col, header=header, \n",
    "                           skiprows=skip_rows) \n",
    "    except OSError:  \n",
    "        print('Cannot read data file {}'.format(file_path))\n",
    "        raise\n",
    "    except:  \n",
    "        raise\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimodal_model(x,x0,s0,a0,x1,s1):\n",
    "    return ( a0*norm.pdf(x, loc=x0,scale=s0)\n",
    "            +(1-a0)*norm.pdf(x, loc=x1,scale=s1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimodal_model(x,x0,s0,a0,x1,s1,a1,x2,s2):\n",
    "    return ( a0*norm.pdf(x, loc=x0,scale=s0)\n",
    "            +a1*norm.pdf(x, loc=x1,scale=s1)\n",
    "            +(1-a0-a1)*norm.pdf(x, loc=x2,scale=s2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kde_pdf(phbs_dict, phb):\n",
    "    raw_df = phbs_dict[phb]['raw_df']\n",
    "    data = np.array(raw_df['Delta_h']).reshape(-1,1)\n",
    "    Delta_h_array = np.linspace(0,1.2*np.max(data),200)\n",
    "    bw = data.std()*(4/3/data.size)**(1/5)*bandwidth_adjustment_factor\n",
    "    print('{}:  bandwidth = {:.0f}'.format(phb,bw))\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bw)\n",
    "    kde.fit(data)\n",
    "    kde_array = np.exp(kde.score_samples(Delta_h_array.reshape(-1,1)))\n",
    "    kde_df = pd.DataFrame(index=None,\n",
    "                          data={'Delta_h': Delta_h_array,\n",
    "                                'p_Delta_h': kde_array})\n",
    "    phbs_dict[phb].update({'kde_df':kde_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_modes(phbs_dict, phb):\n",
    "    kde_df = phbs_dict[phb]['kde_df']\n",
    "    Delta_h_array = kde_df['Delta_h']\n",
    "    p_Delta_h_array = kde_df['p_Delta_h']\n",
    "    peaks_array = find_peaks(p_Delta_h_array)[0]\n",
    "    peaks_array = np.vstack((peaks_array,\n",
    "                             Delta_h_array[peaks_array],\n",
    "                             p_Delta_h_array[peaks_array])).T\n",
    "    peaks_array = np.flipud(peaks_array[peaks_array[:,2].argsort()])\n",
    "    principal_modes_array = peaks_array[:,1:3]\n",
    "    phbs_dict[phb].update({'modes':principal_modes_array})\n",
    "\n",
    "    print(phb)\n",
    "    print('Principal mode#1: ∆h={:.0f}m  p(∆h)={:.5f}'\n",
    "          .format(principal_modes_array[0,0],principal_modes_array[0,1]))\n",
    "    print('Principal mode#2: ∆h={:.0f}m  p(∆h)={:.5f}'\n",
    "          .format(principal_modes_array[1,0],principal_modes_array[1,1]))\n",
    "    if principal_modes_array.shape[0]>2:\n",
    "        print('Principal mode#3: ∆h={:.0f}m  p(∆h)={:.5f}'\n",
    "          .format(principal_modes_array[2,0],principal_modes_array[2,1]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bimodal(phbs_dict, phb):\n",
    "    kde_df          = phbs_dict[phb]['kde_df']\n",
    "    modes_array     = phbs_dict[phb]['modes']\n",
    "    Delta_h_array   = kde_df['Delta_h']\n",
    "    p_Delta_h_array = kde_df['p_Delta_h']\n",
    "    initial_values  = [modes_array[0,0], default_gaussian_stdev, 0.5,\n",
    "                       modes_array[1,0], default_gaussian_stdev]\n",
    "    popt,pcov = curve_fit(bimodal_model, \n",
    "                          Delta_h_array, p_Delta_h_array, \n",
    "                          p0=initial_values)\n",
    "    phbs_dict[phb].update({'bimodal':(popt,pcov)})\n",
    "    \n",
    "    print(phb)\n",
    "#     print(modes_array)\n",
    "    print('Global vertical scale: H_G = {:.0f} ± {:.0f}m'\n",
    "          .format(popt[0],popt[1]))\n",
    "    print('Local vertical scale:  H_L = {:.0f} ± {:.0f}m'\n",
    "          .format(popt[3],popt[4]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_trimodal(phbs_dict, phb):\n",
    "    kde_df          = phbs_dict[phb]['kde_df']\n",
    "    modes_array     = phbs_dict[phb]['modes']\n",
    "    Delta_h_array   = kde_df['Delta_h']\n",
    "    p_Delta_h_array = kde_df['p_Delta_h']\n",
    "    if modes_array.shape[0]>2:\n",
    "        initial_values  = [modes_array[0,0], default_gaussian_stdev, 0.5,\n",
    "                           modes_array[1,0], default_gaussian_stdev, 0.4,\n",
    "                           modes_array[2,0], default_gaussian_stdev]\n",
    "        popt,pcov = curve_fit(trimodal_model, \n",
    "                              Delta_h_array, p_Delta_h_array, \n",
    "                              p0=initial_values)\n",
    "        phbs_dict[phb].update({'trimodal':(popt,pcov)})\n",
    "        print(phb)\n",
    "#         print(modes_array)\n",
    "        print('Global vertical scale: H_G = {:.0f} ± {:.0f}m'\n",
    "              .format(popt[0],popt[1]))\n",
    "        print('Local vertical scale:  H_L = {:.0f} ± {:.0f}m'\n",
    "              .format(popt[3],popt[4]))\n",
    "        print('Extra vertical scale:  H_X = {:.0f} ± {:.0f}m'\n",
    "              .format(popt[6],popt[7]))\n",
    "        print()\n",
    "    else:\n",
    "        print(phb)\n",
    "        print('Two modes only resolved')\n",
    "        print()\n",
    "        phbs_dict[phb].update({'trimodal':(None,None)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defunct - for archiving and possible re-use later\n",
    "def gmm():\n",
    "    nc_list = [2]\n",
    "    gmm_list = [GaussianMixture(n_components=nc,\n",
    "                means_init=peaks_array[0:2,1].reshape(2,1)) \n",
    "                for nc in nc_list]\n",
    "    model_list = [gmm.fit(data) for gmm in gmm_list]\n",
    "    model_aic_list = [model.aic(data) for model in model_list]\n",
    "    best_nc = nc_list[np.argmin(model_aic_list)]\n",
    "    best_model = model_list[np.argmin(model_aic_list)]\n",
    "    best_model_pdf = np.exp(\n",
    "        best_model.score_samples(Delta_h_array.reshape(-1,1)))\n",
    "    best_model_mean= best_model.means_[np.argmax(best_model.precisions_)]\n",
    "    best_model_stdev \\\n",
    "        = np.sqrt(1.0/best_model.precisions_\n",
    "                  [np.argmax(best_model.precisions_)]).ravel()\n",
    "    best_results = np.vstack((np.ravel(best_model.means_),\n",
    "                          np.sqrt(1/best_model.precisions_).ravel())).T\n",
    "    best_results = best_results[best_results[:,1].argsort()]\n",
    "    best_results\n",
    "    best_results[0]\n",
    "\n",
    "\n",
    "    nc = 2\n",
    "    bgmm = BayesianGaussianMixture(n_components=nc,\n",
    "                                   mean_prior=best_model_mean)\n",
    "    bayes_model = bgmm.fit(data)\n",
    "    bayes_model_pdf = np.exp(\n",
    "        bayes_model.score_samples(Delta_h_array.reshape(-1,1)))\n",
    "    bayes_results = np.vstack((np.ravel(bayes_model.means_),\n",
    "                            np.sqrt(1/bayes_model.precisions_).ravel(),\n",
    "                               np.ravel(bayes_model.weights_)\n",
    "                              )).T\n",
    "    bayes_results\n",
    "    bayes_results = bayes_results[bayes_results[:,2].argsort()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model_ph_df = pd.DataFrame(index=None,\n",
    "                data={'Delta_h': Delta_h_array, \n",
    "                      'GMM_pd': best_model_pdf, \n",
    "                      'BGMM_pd': bayes_model_pdf})\n",
    "    model_ph_dict = {}\n",
    "    model_ph_dict.update({data_set_name: model_ph_df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf():\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    plt.plot(Delta_h_array,kde_array, \n",
    "             c='DarkGreen', lw=1,\n",
    "             label='kde pdf')\n",
    "    plt.plot(principal_modes_array[0,0],principal_modes_array[0,1],\n",
    "             'o',ms=8,c='DarkGreen',fillstyle='none')\n",
    "    plt.plot(principal_modes_array[1,0],principal_modes_array[1,1],\n",
    "             's',ms=8,c='DarkGreen',fillstyle='none')\n",
    "    plt.plot(Delta_h_array, bimodal_model(Delta_h_array, *popt),\n",
    "             c='DarkBlue',lw=2,\n",
    "             label='dual Gaussian fit')\n",
    "    plt.plot(popt[0],bimodal_model(popt[0], *popt),\n",
    "             'o',ms=6,c='DarkBlue',\n",
    "             label=r'global scale  $H_G \\approx ${}$\\pm${}m'\\\n",
    "                 .format(int(np.round(popt[0])),int(np.round(popt[1])) ))\n",
    "    plt.plot(popt[3],bimodal_model(popt[3], *popt),\n",
    "             's',ms=6,c='DarkBlue',\n",
    "             label=r' local scale   $H_L \\approx ${}$\\pm${}m'\\\n",
    "                 .format(int(np.round(popt[3])),int(np.round(popt[4])) ))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim(0,)\n",
    "    axes.set_xlim(0,1.2*np.max(ph_df['Delta_h']));\n",
    "    if popt[0]>np.max(ph_df['Delta_h'])/2:\n",
    "        loc='upper left'\n",
    "    else:\n",
    "        loc='upper right'\n",
    "    plt.legend(fontsize=12,loc=loc)\n",
    "    plt.title(data_set_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phbs_group = ['HalfSqKmAc','PHBs','Cusum02_BenchLength3Steps','Tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CostaRica': '/Users/max/Science/ProgHypso/PHscales/CostaRica',\n",
       " 'Finisterres': '/Users/max/Science/ProgHypso/PHscales/Finisterres',\n",
       " 'GabilanMesa': '/Users/max/Science/ProgHypso/PHscales/GabilanMesa',\n",
       " 'SanGabriel': '/Users/max/Science/ProgHypso/PHscales/SanGabriel',\n",
       " 'SantaMarta': '/Users/max/Science/ProgHypso/PHscales/SantaMarta'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_dict = {}\n",
    "for dir in os.listdir(ph_scales_path):\n",
    "    path = os.path.realpath(os.path.join(ph_scales_path,dir))\n",
    "    if dir[0]!='.' and dir!='Analysis' and os.path.isdir(path):\n",
    "        region_dict.update({dir : path})\n",
    "region_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/max/Science/ProgHypso/PHscales/GabilanMesa/HalfSqKmAc/PHBs/Cusum02_BenchLength3Steps/Tables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bebeb7799359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphbs_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     supercatchment_list = [(path,supercatchment)\n\u001b[0;32m----> 5\u001b[0;31m                             \u001b[0;32mfor\u001b[0m \u001b[0msupercatchment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                             if supercatchment[0]!='.']\n\u001b[1;32m      7\u001b[0m     \u001b[0msupercatchment_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mregion\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msupercatchment_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/max/Science/ProgHypso/PHscales/GabilanMesa/HalfSqKmAc/PHBs/Cusum02_BenchLength3Steps/Tables'"
     ]
    }
   ],
   "source": [
    "supercatchment_dict = {}\n",
    "for region in region_dict:\n",
    "    path = os.path.join(region_dict[region],*phbs_group)\n",
    "    supercatchment_list = [(path,supercatchment)\n",
    "                            for supercatchment in os.listdir(path) \n",
    "                            if supercatchment[0]!='.']\n",
    "    supercatchment_dict.update({region : supercatchment_list})\n",
    "supercatchment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phbs_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for supercatchment in supercatchment_dict.keys():\n",
    "    for phbs in supercatchment_dict[supercatchment]:\n",
    "        name = supercatchment+'_'+phbs[1].replace('.txt','')\n",
    "        path = (phbs[0],phbs[1])\n",
    "        df = read_data(dir_name=[phbs[0]], \n",
    "                          file_name=phbs[1], index_col=None)\n",
    "        phbs_dict.update({name : {'path':phbs[0],\n",
    "                                  'file':phbs[1],\n",
    "                                  'raw_df':  df} })\n",
    "\n",
    "list(phbs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_phb = list(phbs_dict.keys())[example_phb_index]\n",
    "df = phbs_dict[example_phb]['raw_df']\n",
    "axes = df.plot.scatter(x='Outlets',y='Modes',title=example_phb)\n",
    "axes.set_ylim(0,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every supercatchment result table (now in a `pandas` dataframe), compute $\\Delta{h} = h_\\mathrm{mode}-h_\\mathrm{outlet}$ and put into a new column in that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phb in phbs_dict:\n",
    "    df = phbs_dict[phb]['raw_df']\n",
    "    df['Delta_h'] = df['Modes']-df['Outlets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the pdf $p(\\Delta{h})$ for an example super."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_phb = list(phbs_dict.keys())[example_phb_index]\n",
    "\n",
    "df = phbs_dict[example_phb]['raw_df']\n",
    "axes = df.plot.density(x='Outlets',y='Delta_h',bw_method='silverman',\n",
    "                          title=example_phb)\n",
    "axes.set_xlim(0,1.1*np.max(df['Delta_h']));\n",
    "axes.set_ylim(0,);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a kernel-density estimated pdf for each super, and place in another dataframe for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phb in phbs_dict:\n",
    "    compute_kde_pdf(phbs_dict, phb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example super, compare this kde pdf with the one generated and plotted above by `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_phb = list(phbs_dict.keys())[example_phb_index]\n",
    "df = phbs_dict[example_phb]['kde_df']\n",
    "axes = df.plot.line(x='Delta_h',y='p_Delta_h',\n",
    "                          title=example_phb)\n",
    "axes.set_xlim(0,np.max(df['Delta_h']));\n",
    "axes.set_ylim(0,);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phb in phbs_dict:\n",
    "    modes = find_modes(phbs_dict, phb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phb in phbs_dict:\n",
    "    fit_bimodal(phbs_dict, phb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phb in phbs_dict:\n",
    "    fit_trimodal(phbs_dict, phb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
